{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011d1306-0ae1-47d9-a0bc-c05e7fcaaded",
   "metadata": {},
   "source": [
    "# WEB SCRAPING PROJECT\n",
    "### Moi Kapsowar Girls High School KCSE Results Analysis\n",
    "\n",
    "In this project, I developed a **Python-based web scraping** solution to extract and structure tabular Kenya Certificate of Secondary Education (KCSE) data from the webpage of *Moi Kapsowar Girls*.\n",
    "\n",
    "By utilizing libraries such as **BeautifulSoup** for HTML parsing and **pandas** for data manipulation, I successfully extracted two key tables from the website.\n",
    "Since I realized the tables lacked headers, I manually defined and assigned appropriate column names to ensure data integrity.\n",
    "\n",
    "The data was then structured, and saved in CSV format for further analysis.\n",
    "\n",
    "### Source of Data:\n",
    "[Moi Kapsowar Girls High School Website](https://moikapsowargirls.sc.ke/kcse-results-analysis/)\n",
    "\n",
    "## The Process\n",
    "1. [Importing the Required Libraries](#importing_the_required_libraries)\n",
    "2. [Fetching the Webpage Content](#fetching_the_webpage_content)\n",
    "3. [Parsing the HTML Content with BeautifulSoup](#parsing_the_html_content_with_beautifulsoup)\n",
    "4. [Finding All Tables on the Webpage](#finding_all_tables_on_the_webpage)\n",
    "5. [Extracting the First Table](#extracting_the_first_table)\n",
    "6. [Extracting the Second Table](#extracting_the_second_table)\n",
    "7. [Verifing the Output](#verifing_the_output)\n",
    "\n",
    "### Importing the Required Libraries\n",
    "I started by importing the necessary libraries:\n",
    "- **requests** to fetch the webpage,\n",
    "- **BeautifulSoup** to parse the HTML,\n",
    "- and **pandas** to manage and manipulate the table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f3d0e7-dead-48af-987c-73c40346eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I already had the required Python libraries installed.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c967a-6fa4-4c98-b2d9-ede8aec825f9",
   "metadata": {},
   "source": [
    "### Fetching the Webpage Content\n",
    "Next, I sent a GET request to the website to retrieve the HTML content of the page.\n",
    "\n",
    "*This step ensures that the content of the page is accessible for parsing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e4c91f-2056-4992-b2bb-06d686e22e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://moikapsowargirls.sc.ke/kcse-results-analysis/'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Request was successful!\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bb1cb-389d-4517-80d5-8cbd6adf5a0a",
   "metadata": {},
   "source": [
    "### Parsing the HTML Content with BeautifulSoup\n",
    "I then used BeautifulSoup to parse the HTML content of the webpage.\n",
    "\n",
    "*This would allow me to navigate the HTML structure and locate the specific elements I was interested in, which was the two KCSE results tables on the site.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dc3d7d-8ecc-4b0f-aad7-bc2ae53c7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3c436-76d1-4dd3-859f-c9e75fa26d12",
   "metadata": {},
   "source": [
    "### Finding All Tables on the Webpage\n",
    "I then sought to find all the table elements on the page and store them in a list.\n",
    "\n",
    "I could thereafter access each of the two tables easily, by using its index in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95eb58b0-76b5-47ae-95a1-e313e7b33161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 tables.\n"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('table')\n",
    "print(f\"Found {len(tables)} tables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514afc8-9ec2-47bc-9bd4-e76fc600e595",
   "metadata": {},
   "source": [
    "### Extracting the First Table\n",
    "Since I noted (while inspecting the HTML component) that the tables had no headers, I manually defined them based on the contents of the table.\n",
    "\n",
    "Then while extracting the data from the first table (by iterating over the rows), I started from the second row, skipping the first row which had the header contents since it was not part of the KCSE result data.\n",
    "\n",
    "Finally, I saved the extracted data from the first table to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e348eb68-2573-4af5-8587-eeff8a18a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_first_table = [\"Stream\", \"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"E\", \"X\", \"Y\", \"ENTRIES\", \"MEAN POINTS\", \"MP DEV\", \"GRADE\"]\n",
    "\n",
    "first_table = tables[0]\n",
    "rows_first_table = first_table.find_all('tr')\n",
    "\n",
    "data_first_table = []\n",
    "for row in rows_first_table[1:]:\n",
    "    # Skipping the first row\n",
    "    cells = row.find_all('td')\n",
    "    data_first_table.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "# Creating the DataFrame using the manually defined headers\n",
    "df_first_table = pd.DataFrame(data_first_table, columns=headers_first_table)\n",
    "\n",
    "file_path_first_table = 'C:/Users/Patricia/Documents/KCSE 2021 RESULTS ANALYSIS.csv'\n",
    "# The file is saved as it was named in the site, to the documents section in my laptop.\n",
    "df_first_table.to_csv(file_path_first_table, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb531c-37d4-43fe-acd7-203c7b734057",
   "metadata": {},
   "source": [
    "### Extracting the Second Table\n",
    "I defined the headers for the second table, similarly to how I did for the first table.\n",
    "\n",
    "I then extracted the data from the second table by iterating over its rows, again skipping the first row.\n",
    "\n",
    "I lastly saved the extracted data from the second table to another CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10b7dc3-1298-4701-b590-a8dea6019463",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_second_table = [\"Stream\", \"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"E\", \"X\", \"Y\", \"ENTRIES\", \"MEAN POINTS\", \"MP DEV\", \"GRADE\"]\n",
    "\n",
    "second_table = tables[1]\n",
    "rows_second_table = second_table.find_all('tr')\n",
    "\n",
    "data_second_table = []\n",
    "for row in rows_second_table[1:]:\n",
    "    # Skipping the first row again\n",
    "    cells = row.find_all('td')\n",
    "    data_second_table.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "# Creating the DataFrame using the manually defined headers\n",
    "df_second_table = pd.DataFrame(data_second_table, columns=headers_second_table)\n",
    "\n",
    "file_path_second_table = 'C:/Users/Patricia/Documents/KCSE 2020 RESULTS ANALYSIS.csv'\n",
    "# Again, the csv file is saved as it was named in the site, to the documents section in my laptop.\n",
    "df_second_table.to_csv(file_path_second_table, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d3aee-ead9-4641-a64f-3c99ff0c9f77",
   "metadata": {},
   "source": [
    "### Verifing the Output\n",
    "Eventually, after successfully extracting the data from the two tables, I printed the first few rows of each DataFrame to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4228d1d4-315e-4a72-b43a-1619eaed6e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stream  A A- B+   B  B-  C+   C C- D+  D D-  E  X  Y ENTRIES MEAN POINTS  \\\n",
      "0     EAST  0  1  5   8  17  13   7  2  1  0  0  0  0  0      54      7.7037   \n",
      "1    NORTH  0  1  3  10   8  15   8  5  0  0  0  0  0  0      50        7.46   \n",
      "2    SOUTH  0  0  4   9  11  13  12  3  1  1  0  0  0  0      54      7.2963   \n",
      "3     WEST  0  0  1  13  14   6  13  3  4  0  0  0  0  0      54      7.2222   \n",
      "4  CENTRAL  0  0  1   5  10  11  13  7  6  0  0  0  0  0      53      6.5849   \n",
      "\n",
      "   MP DEV GRADE  \n",
      "0  1.5185    B-  \n",
      "1    1.64    C+  \n",
      "2  1.2407    C+  \n",
      "3  1.0556    C+  \n",
      "4   1.258    C+  \n",
      "  Stream  A A-  B+   B  B-  C+   C  C- D+  D D-  E  X  Y ENTRIES MEAN POINTS  \\\n",
      "0  SOUTH  0  3   3  12  11  15   4   3  0  0  0  0  1  0      52       7.902   \n",
      "1   EAST  0  3   4   8   8  16   5   5  0  0  0  0  0  0      49      7.6735   \n",
      "2  NORTH  0  0   8  11  10   7  15   3  0  0  0  0  0  0      54      7.6481   \n",
      "3   WEST  0  1   2  12   6  14   9   7  0  0  0  0  1  0      52      7.3333   \n",
      "4  TOTAL  0  7  17  43  35  52  33  18  0  0  0  0  2  0     207       7.639   \n",
      "\n",
      "   MP DEV GRADE  \n",
      "0  0.7183    B-  \n",
      "1  0.9427    B-  \n",
      "2  0.7854    B-  \n",
      "3  0.7564    C+  \n",
      "4  0.8057    B-  \n"
     ]
    }
   ],
   "source": [
    "# First table data\n",
    "print(df_first_table.head())\n",
    "\n",
    "# Second table data\n",
    "print(df_second_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a23c9c-5254-4504-8ddc-3f2d99755c35",
   "metadata": {},
   "source": [
    "### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
